{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This part is aleady extracted to .py file, skip it from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import segment_imgs, read_to_rgb, quantify_fov\n",
    "from covid_screening_quantify import sort_wells_fovs, quantify_all_fovs, combine_all_quantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHS_MAPPING = {\n",
    "    'nuclei': 'ch1',\n",
    "    'er': 'ch2',\n",
    "    'virus': 'ch3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_wells_fovs(image_folder):\n",
    "    \"\"\"\n",
    "    sort the wells and fovs in an image folder\n",
    "    \n",
    "    Args:\n",
    "        image_folder (str): path of image folder, which hosts all the images.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: wells and fovs list\n",
    "    \"\"\"\n",
    "    files = os.listdir(image_folder)\n",
    "    files = list(\n",
    "        filter(\n",
    "            lambda item:\n",
    "                item if item.endswith('.tiff') and not item.startswith('.') else None,\n",
    "            files\n",
    "        )\n",
    "    )\n",
    "    fovs = [file[:9] for file in files]\n",
    "    fovs = list(set(fovs))\n",
    "    fovs.sort()\n",
    "    wells = [fov[:6] for fov in fovs]\n",
    "    wells = list(set(wells))\n",
    "    wells.sort()\n",
    "    \n",
    "    return wells, fovs, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_all_fovs(image_folder, processed_folder=None, save_mask=True, quantify_directly=True):\n",
    "    \"\"\"\n",
    "    Quantify all the fovs in image folder.\n",
    "    \n",
    "    Args:\n",
    "        image_folder (str): path to folder where hosts all the images.\n",
    "        save_mask (bool): to save mask as file or not.\n",
    "        quantify_directly (bool): to quantify the cell data directly or not.\n",
    "    \n",
    "    Returns:\n",
    "        str: the path of processed folder.\n",
    "    \"\"\"\n",
    "    wells, fovs, files = sort_wells_fovs(image_folder)\n",
    "    # create processed folder if to save files\n",
    "    if not processed_folder:\n",
    "        processed_folder = image_folder + '_processed'\n",
    "    if save_mask or quantify_directly:\n",
    "        os.makedirs(processed_folder, exist_ok=True)\n",
    "\n",
    "    for _, well_id in enumerate(wells):\n",
    "        # get all the fovs for the well\n",
    "        well_fovs = list(\n",
    "            filter(\n",
    "                lambda fov: fov if fov[:6] == well_id else None, fovs\n",
    "            )\n",
    "        )\n",
    "        well_fovs.sort()\n",
    "        for _, well_fov in enumerate(well_fovs):\n",
    "            # set the output for fov_data_output\n",
    "            fov_data_output = []\n",
    "            # get all the files for a fov\n",
    "            fov_files = list(\n",
    "                filter(\n",
    "                    lambda file: file if well_fov in file else None, files\n",
    "                )\n",
    "            )\n",
    "            fov_files.sort()\n",
    "            # this part is a simple assertation to make sure only one plane in zstack.\n",
    "            # Otherwise, changes are needed fot this pipeline\n",
    "            planes = [fov_file.split('-')[0] for fov_file in fov_files]\n",
    "            planes = set(planes)\n",
    "            assert len(planes) == 1, \"This pipeline requires single plane image, but multiple planes/z-stack images found!\"\n",
    "\n",
    "            #CHS_MAPPING\n",
    "            nuclei_file = list(\n",
    "                filter(\n",
    "                    lambda fov_file:\n",
    "                        fov_file if fov_file.split('-')[1][:3] == CHS_MAPPING['nuclei'] else None,\n",
    "                    fov_files\n",
    "                )\n",
    "            )\n",
    "            er_file = list(\n",
    "                filter(\n",
    "                    lambda fov_file:\n",
    "                        fov_file if fov_file.split('-')[1][:3] == CHS_MAPPING['er'] else None,\n",
    "                    fov_files\n",
    "                )\n",
    "            )\n",
    "            virus_file = list(\n",
    "                filter(\n",
    "                    lambda fov_file:\n",
    "                        fov_file if fov_file.split('-')[1][:3] == CHS_MAPPING['virus'] else None,\n",
    "                    fov_files\n",
    "                )\n",
    "            )\n",
    "            assert len(nuclei_file) == len(er_file) == len(virus_file) == 1, \"{} should have only one file for each channel!\".format(well_fov)\n",
    "\n",
    "            fov_chs_files = {\n",
    "                'nuclei': os.path.join(image_folder, nuclei_file[0]),\n",
    "                'er': os.path.join(image_folder, er_file[0]),\n",
    "                'virus': os.path.join(image_folder, virus_file[0])\n",
    "            }\n",
    "\n",
    "            # read image files to rgb img array with virus in r, er in g, nuclei in b\n",
    "            fov_chs_rgb, channel =  read_to_rgb(fov_chs_files)\n",
    "\n",
    "            # segment the cell images\n",
    "            results = segment_imgs([fov_chs_rgb], [channel])\n",
    "            mask = results['masks'][0]\n",
    "            # save mask data to file, if save_mask is true\n",
    "            if save_mask:\n",
    "                mask = np.asarray(mask, dtype='uint16')\n",
    "                mask_file = os.path.join(processed_folder, well_fov + '_mask.png')\n",
    "                imageio.imwrite(mask_file, mask, format='PNG-FI')\n",
    "\n",
    "            # skip the quantificaiton if quantify_directly is false\n",
    "            if not quantify_directly:\n",
    "                continue\n",
    "            # calculate the intensity\n",
    "            fov_quantify = quantify_fov(fov_chs_rgb[:,:,0], mask)\n",
    "            # if no cells, continue\n",
    "            if not len(fov_quantify):\n",
    "                continue\n",
    "\n",
    "            # write data to list, and then to csv file\n",
    "            for cell_data in fov_quantify:\n",
    "                cell_idx, cell_size, cell_integ, cell_mean = cell_data\n",
    "\n",
    "                cell_info = {}\n",
    "                cell_info['well_id'] = well_id\n",
    "                cell_info['well_fovs'] = well_fov\n",
    "                cell_info['nuclei_file'] = fov_chs_files['nuclei']\n",
    "                cell_info['er_file'] = fov_chs_files['er']\n",
    "                cell_info['virus_file'] = fov_chs_files['virus']\n",
    "                cell_info['cell_idx'] = cell_idx\n",
    "                cell_info['cell_size'] = cell_size\n",
    "                cell_info['cell_integ'] = cell_integ\n",
    "                cell_info['cell_mean'] = cell_mean\n",
    "                # append the data to fov_data_output\n",
    "                fov_data_output.append(cell_info)\n",
    "            # save the data from each fov to csv file\n",
    "            df = pd.DataFrame(fov_data_output)\n",
    "            csv_file = os.path.join(processed_folder, well_fov + '_quantify.csv')\n",
    "\n",
    "            df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    return processed_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_quantify(processed_folder, combine_file=True):\n",
    "    \"\"\"\n",
    "    Combine fov quantify csv into one combined csv file.\n",
    "    \n",
    "    Args:\n",
    "        processed_folder (str): the path of processed folder.\n",
    "        combine_file (bool): save combined csv if true, else not.\n",
    "    \"\"\"\n",
    "    quantify_csvs = glob(processed_folder + '/*_quantify.csv')\n",
    "    quantiy_csvs = list(\n",
    "        filter(\n",
    "            lambda quantify_csv:\n",
    "                quantify_csv if not os.path.basename(quantify_csv).startswith('.') else None,\n",
    "            quantify_csvs\n",
    "        )\n",
    "    )\n",
    "    quantiy_csvs.sort()\n",
    "    dfs = []\n",
    "    for _, quantify_csv in enumerate(quantify_csvs):\n",
    "        try:\n",
    "            df = pd.read_csv(quantify_csv)\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'{quantify_csv} cannot be successfully read!')\n",
    "    df = pd.concat(dfs)\n",
    "    if combine_file:\n",
    "        df.to_csv(\n",
    "            '/home/haoxu/data/test_data_20201218/40x_processed/quantify_all.csv',\n",
    "            index=False\n",
    "        )\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skip till here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do test from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** TORCH CUDA version installed and working. **\n"
     ]
    }
   ],
   "source": [
    "from covid_screening_quantify import sort_wells_fovs, quantify_all_fovs, combine_all_quantify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test parameter\n",
    "image_folder = '/home/haoxu/data/test_data_20201218/40x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.15s; flow+mask computation 1.59\n",
      "estimated cell diameters for 1 image(s) in 2.17 sec\n",
      ">>> diameter(s) =  [72.92151461]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoxu/miniconda3/envs/cellpose_torch/lib/python3.7/site-packages/torch/nn/functional.py:3385: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time spent: running network 0.37s; flow+mask computation 0.23\n",
      "estimated masks for 1 image(s) in 0.64 sec\n",
      ">>>> TOTAL TIME 2.81 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.21s; flow+mask computation 2.12\n",
      "estimated cell diameters for 1 image(s) in 2.75 sec\n",
      ">>> diameter(s) =  [79.18374949]\n",
      "time spent: running network 0.38s; flow+mask computation 0.19\n",
      "estimated masks for 1 image(s) in 0.61 sec\n",
      ">>>> TOTAL TIME 3.36 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.14s; flow+mask computation 1.95\n",
      "estimated cell diameters for 1 image(s) in 2.52 sec\n",
      ">>> diameter(s) =  [94.46133999]\n",
      "time spent: running network 0.26s; flow+mask computation 0.17\n",
      "estimated masks for 1 image(s) in 0.47 sec\n",
      ">>>> TOTAL TIME 3.00 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.21s; flow+mask computation 1.85\n",
      "estimated cell diameters for 1 image(s) in 2.47 sec\n",
      ">>> diameter(s) =  [80.71942351]\n",
      "time spent: running network 0.38s; flow+mask computation 0.19\n",
      "estimated masks for 1 image(s) in 0.60 sec\n",
      ">>>> TOTAL TIME 3.07 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.21s; flow+mask computation 2.05\n",
      "estimated cell diameters for 1 image(s) in 2.67 sec\n",
      ">>> diameter(s) =  [65.51404815]\n",
      "time spent: running network 0.38s; flow+mask computation 0.24\n",
      "estimated masks for 1 image(s) in 0.65 sec\n",
      ">>>> TOTAL TIME 3.32 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.20s; flow+mask computation 2.03\n",
      "estimated cell diameters for 1 image(s) in 2.63 sec\n",
      ">>> diameter(s) =  [94.18418077]\n",
      "time spent: running network 0.26s; flow+mask computation 0.18\n",
      "estimated masks for 1 image(s) in 0.48 sec\n",
      ">>>> TOTAL TIME 3.12 sec\n",
      "** TORCH CUDA version installed and working. **\n",
      ">>>> using GPU\n",
      "processing 1 image(s)\n",
      "computing styles from images\n",
      "time spent: running network 0.14s; flow+mask computation 1.83\n",
      "estimated cell diameters for 1 image(s) in 2.38 sec\n",
      ">>> diameter(s) =  [91.87806148]\n",
      "time spent: running network 0.26s; flow+mask computation 0.17\n",
      "estimated masks for 1 image(s) in 0.47 sec\n",
      ">>>> TOTAL TIME 2.85 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/haoxu/data/test_data_20201218/40x_processed'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantify_all_fovs(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_folder = os.path.join(acquisition_folder, \"Images\")\n",
    "#image_folder = '/home/haoxu/data/test_data_20201218/40x'\n",
    "#save_mask = False\n",
    "#quantify_directly = True\n",
    "#process_folder = image_folder + '_processed'\n",
    "#if save_mask or quantify_directly:\n",
    "#    os.makedirs(process_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up function\n",
    "    # image reader\n",
    "    # segmentation\n",
    "    # quantification\n",
    "    # put all quantification into one file\n",
    "    # define cell infection\n",
    "    # verify cell_infectionS\n",
    "    # statistics output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_folder = '/home/haoxu/data/test_data_20201218/40x_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_all_quantify(processed_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiy_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/haoxu/data/test_data_20201218/40x_processed/quantify_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity = df.cell_mean.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.hist(intensity, bins=70, range=(min(intensity), max(intensity)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
